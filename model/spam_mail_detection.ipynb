{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "UBGPH0VtIyxr",
    "outputId": "30a56873-8714-4926-d6dc-b00e3c0de19e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import _stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wB9EGf7fIyxw"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/spamham.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['spam', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data[['text','spam']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "id": "zWG8DrwIIyxy",
    "outputId": "58e505e4-49cc-4ab1-c36c-a174fca52060"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sOgIC9vgIyx5"
   },
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CKqqW3y0Iyx5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "emails_train, emails_test, target_train, target_test = train_test_split(data.text,data.spam,test_size = 0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "FhaVY-xSIyx8",
    "outputId": "7906aa91-2687-4dba-b4d2-138053e92d76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       spam                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will Ã¼ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "u_7DJm1kIyx-",
    "outputId": "b45844ac-0b99-4a58-dea7-7ba2d5cd7aac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W5cfcZhuIyyF"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "UVDFx5cIIyyF",
    "outputId": "c566c50a-9e93-4b36-95e9-ca0840d07a15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'darren was saying dat if u meeting da ge den we dun meet  dinner cos later u leave xy will feel awkward den u meet him  lunch lor'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_hyperlink(word):\n",
    "    return  re.sub(r\"http\\S+\", \"\", word)\n",
    "\n",
    "def to_lower(word):\n",
    "    result = word.lower()\n",
    "    return result\n",
    "\n",
    "def remove_number(word):\n",
    "    result = re.sub(r'\\d+', '', word)\n",
    "    return result\n",
    "\n",
    "def remove_punctuation(word):\n",
    "    result = word.translate(str.maketrans(dict.fromkeys(string.punctuation)))\n",
    "    return result\n",
    "\n",
    "def remove_whitespace(word):\n",
    "    result = word.strip()\n",
    "    return result\n",
    "\n",
    "def replace_newline(word):\n",
    "    return word.replace('\\n','')\n",
    "\n",
    "\n",
    "\n",
    "def clean_up_pipeline(sentence):\n",
    "    cleaning_utils = [remove_hyperlink,\n",
    "                      replace_newline,\n",
    "                      to_lower,\n",
    "                      remove_number,\n",
    "                      remove_punctuation,remove_whitespace]\n",
    "    for o in cleaning_utils:\n",
    "        sentence = o(sentence)\n",
    "    return sentence\n",
    "\n",
    "x_train = [clean_up_pipeline(o) for o in emails_train]\n",
    "x_test = [clean_up_pipeline(o) for o in emails_test]\n",
    "\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J6m0KYITIyyI"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train_y = le.fit_transform(target_train.values)\n",
    "test_y = le.transform(target_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "p8nTaChYIyyK",
    "outputId": "7d1dc3d4-00e1-4ffe-b44f-a372b6f2b234"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NQnP3LyeIyyN"
   },
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hRfyW-pHIyyN"
   },
   "outputs": [],
   "source": [
    "## some config values \n",
    "embed_size = 100 # how big is each word vector\n",
    "max_feature = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "max_len = 2000 # max number of words in a question to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4pU9YkDwIyyQ",
    "outputId": "148519e4-a021-4f79-8ad1-a77d33e69943"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\90552\\AppData\\Local\\Temp\\ipykernel_1206392\\3475507181.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train_features = np.array(tokenizer.texts_to_sequences(x_train))\n",
      "C:\\Users\\90552\\AppData\\Local\\Temp\\ipykernel_1206392\\3475507181.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test_features = np.array(tokenizer.texts_to_sequences(x_test))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([list([740, 59, 560, 315, 31, 6, 255, 94, 1035, 369, 37, 239, 179, 329, 160, 95, 6, 228, 941, 27, 200, 3482, 369, 6, 179, 124, 262, 74]),\n",
       "       list([136, 10, 4, 1529, 2, 92, 92, 77, 14]),\n",
       "       list([269, 543, 34, 68, 8, 4, 587]),\n",
       "       list([269, 543, 182, 100, 2, 6, 4, 741, 544, 111, 3483, 229]),\n",
       "       list([4, 316, 256, 20, 32, 5, 516, 22, 32, 5, 1845, 35, 1846, 7, 3484]),\n",
       "       list([270, 107, 25, 1, 2389, 1847, 7, 3485, 7, 351, 475, 36, 295, 1, 257, 287, 18, 2390, 25, 1, 330, 13, 207, 9, 1332, 438, 19, 14, 44, 1530]),\n",
       "       list([32, 53, 64, 130, 1, 60, 140]),\n",
       "       list([80, 22, 230, 41, 21, 200, 144, 338, 1333, 3486, 19, 942, 10, 208]),\n",
       "       list([99, 35, 13, 231, 7, 517, 7, 3, 27, 271, 71, 647, 4, 588, 864, 48, 3487, 32, 1848, 3488, 1531, 3489, 1849]),\n",
       "       list([80, 55, 16, 95])], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_feature)\n",
    "\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "x_train_features = np.array(tokenizer.texts_to_sequences(x_train))\n",
    "x_test_features = np.array(tokenizer.texts_to_sequences(x_test))\n",
    "\n",
    "x_train_features[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wYBAvFS-IyyT"
   },
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "J9qrzRgtIyyU",
    "outputId": "ac175ed2-c597-4ffa-8482-11005e43f204"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  124,  262,   74],\n",
       "       [   0,    0,    0, ...,   92,   77,   14],\n",
       "       [   0,    0,    0, ...,    8,    4,  587],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  942,   10,  208],\n",
       "       [   0,    0,    0, ..., 1531, 3489, 1849],\n",
       "       [   0,    0,    0, ...,   55,   16,   95]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "x_train_features = pad_sequences(x_train_features,maxlen=max_len)\n",
    "x_test_features = pad_sequences(x_test_features,maxlen=max_len)\n",
    "x_train_features[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cNJGhByLIyyZ"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ppV2YhHIyyZ"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "1nXG9MfEKWzx",
    "outputId": "37a54edf-e617-4e58-8a53-af7e27d246ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 2000, 32)          1600000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              49664     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                2064      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,651,745\n",
      "Trainable params: 1,651,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "import tensorflow as tf\n",
    "embedding_vecor_length = 32\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Embedding(max_feature, embedding_vecor_length, input_length=max_len))\n",
    "model.add(Bidirectional(tf.keras.layers.LSTM(64)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 728
    },
    "colab_type": "code",
    "id": "n_oFHNH6Iyye",
    "outputId": "5c6679ba-7125-4460-a8a1-3dc63b3e0f7a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35/35 [==============================] - 20s 269ms/step - loss: 0.5034 - accuracy: 0.8342 - val_loss: 0.3663 - val_accuracy: 0.8610\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 8s 237ms/step - loss: 0.2167 - accuracy: 0.9206 - val_loss: 0.1311 - val_accuracy: 0.9552\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 8s 237ms/step - loss: 0.0603 - accuracy: 0.9856 - val_loss: 0.0855 - val_accuracy: 0.9740\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 8s 240ms/step - loss: 0.0288 - accuracy: 0.9924 - val_loss: 0.1035 - val_accuracy: 0.9767\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 9s 246ms/step - loss: 0.0216 - accuracy: 0.9955 - val_loss: 0.0775 - val_accuracy: 0.9785\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 8s 237ms/step - loss: 0.0144 - accuracy: 0.9980 - val_loss: 0.0667 - val_accuracy: 0.9776\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 8s 238ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.1273 - val_accuracy: 0.9758\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 9s 244ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.0855 - val_accuracy: 0.9785\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 9s 248ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.1015 - val_accuracy: 0.9785\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 9s 248ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0746 - val_accuracy: 0.9821\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_features, train_y, batch_size=128, epochs=10, validation_data=(x_test_features, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TzGF_hA4Jg3m"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,f1_score, precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkJQ-yURJg3n"
   },
   "outputs": [],
   "source": [
    "y_predict  = [1 if o>0.5 else 0 for o in model.predict(x_test_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gB21196PJg3o"
   },
   "outputs": [],
   "source": [
    "cf_matrix =confusion_matrix(test_y,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kberNYWIJg3r"
   },
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(test_y,y_predict).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "kshhXwFAJg3s",
    "outputId": "91b1d31b-ec7c-48cc-fef2-8d28fd31a397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 98.56%\n",
      "Recall: 88.39%\n",
      "F1 Score: 93.20%\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(test_y, y_predict)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(test_y, y_predict)))\n",
    "print(\"F1 Score: {:.2f}%\".format(100 * f1_score(test_y,y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x8pacWZkJg3v",
    "outputId": "de04c7a1-3d2c-46bd-cacb-c985b2316527",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9319727891156463"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_y,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "#model.save('model.h5')\n",
    "\n",
    "model_final = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = np.array(tokenizer.texts_to_sequences([\"WINNER!! As a valued network customer you have been selected to receivea Â£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 629,   76,    4,  768,  428,  216,    3,   17,  100,  425,    2,\n",
       "        7662,  143,  966,    2,  125,   16,  125,  426,  511,  510,   65]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ..., 511, 510,  65]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features = pad_sequences(text,maxlen=max_len)\n",
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict  = [1 if o>0.5 else 0 for o in model_final.predict(test_features)]\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('WINNER!! As a valued network customer you have been selected to receivea Â£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.', 0, 'Ham')]\n"
     ]
    }
   ],
   "source": [
    "def predict(model, sample_mail):\n",
    "    \n",
    "    pred_to_label = {0: 'Ham', 1: 'Spam'}\n",
    "    \n",
    "    text = np.array(tokenizer.texts_to_sequences([sample_mail]))\n",
    "    test_features = pad_sequences(text,maxlen=max_len)\n",
    "    \n",
    "    y_predict  = [1 if o>0.5 else 0 for o in model.predict(test_features)]\n",
    "    \n",
    "\n",
    "    data = []\n",
    "    for mail, pred in zip(sample_mail, y_predict):\n",
    "        data.append((mail, pred, pred_to_label[pred]))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # Text to classify should be in a list.\n",
    "    \n",
    "    sample_mail = [\"WINNER!! As a valued network customer you have been selected to receivea Â£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\"]\n",
    "\n",
    "    \n",
    "    predictions = predict(model_final, sample_mail)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "sOgIC9vgIyx5"
   ],
   "include_colab_link": true,
   "name": "SpamDetection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mail",
   "language": "python",
   "name": "mail"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
